{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b6796b-f2df-439a-82ef-f8a8fa417f06",
   "metadata": {},
   "source": [
    "XGBOOST CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc371d38-a96e-441d-a15c-bc8c95ae1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIG\n",
    "# ==========================================\n",
    "INPUT_CSV = \"final_ml_features_normalized - final_ml_features_normalized.csv\"\n",
    "TARGET_COL = \"Median_Housing_Value_2023\"\n",
    "RANDOM_STATE = 1738\n",
    "TEST_SIZE = 0.2\n",
    "N_SPLITS = 5\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA + BASIC CLEANUP\n",
    "# ==========================================\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print(\"Original shape:\", df.shape)\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[TARGET_COL])\n",
    "print(\"After dropping missing target:\", df.shape)\n",
    "\n",
    "# Build city/state from Merge_Key if needed\n",
    "if \"state\" not in df.columns or \"city\" not in df.columns:\n",
    "    if \"Merge_Key\" in df.columns:\n",
    "        city_state = df[\"Merge_Key\"].astype(str).str.split(\",\", n=1, expand=True)\n",
    "        df[\"city\"] = city_state[0].str.strip()\n",
    "        df[\"state\"] = city_state[1].str.strip()\n",
    "        print(\"Derived 'city' and 'state' from Merge_Key.\")\n",
    "    else:\n",
    "        raise ValueError(\"Need 'state' or 'Merge_Key' to create geographic features.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ADD REGION COLUMN (GEOGRAPHIC EMBEDDING)\n",
    "# ==========================================\n",
    "state_to_region = {\n",
    "    # Northeast\n",
    "    \"ME\": \"Northeast\", \"NH\": \"Northeast\", \"VT\": \"Northeast\", \"MA\": \"Northeast\",\n",
    "    \"RI\": \"Northeast\", \"CT\": \"Northeast\", \"NY\": \"Northeast\", \"NJ\": \"Northeast\",\n",
    "    \"PA\": \"Northeast\",\n",
    "    # Midwest\n",
    "    \"OH\": \"Midwest\", \"IN\": \"Midwest\", \"IL\": \"Midwest\", \"MI\": \"Midwest\",\n",
    "    \"WI\": \"Midwest\", \"MN\": \"Midwest\", \"IA\": \"Midwest\", \"MO\": \"Midwest\",\n",
    "    \"ND\": \"Midwest\", \"SD\": \"Midwest\", \"NE\": \"Midwest\", \"KS\": \"Midwest\",\n",
    "    # South\n",
    "    \"DE\": \"South\", \"MD\": \"South\", \"DC\": \"South\", \"VA\": \"South\", \"WV\": \"South\",\n",
    "    \"NC\": \"South\", \"SC\": \"South\", \"GA\": \"South\", \"FL\": \"South\",\n",
    "    \"KY\": \"South\", \"TN\": \"South\", \"MS\": \"South\", \"AL\": \"South\",\n",
    "    \"OK\": \"South\", \"TX\": \"South\", \"AR\": \"South\", \"LA\": \"South\",\n",
    "    # West\n",
    "    \"MT\": \"West\", \"ID\": \"West\", \"WY\": \"West\", \"CO\": \"West\", \"NM\": \"West\",\n",
    "    \"AZ\": \"West\", \"UT\": \"West\", \"NV\": \"West\", \"WA\": \"West\", \"OR\": \"West\",\n",
    "    \"CA\": \"West\", \"AK\": \"West\", \"HI\": \"West\",\n",
    "}\n",
    "df[\"region\"] = df[\"state\"].map(state_to_region).fillna(\"Other\")\n",
    "\n",
    "print(\"\\nSample of city/state/region:\")\n",
    "print(df[[\"city\", \"state\", \"region\"]].head())\n",
    "\n",
    "# ==========================================\n",
    "# 3. STRICT 2021‚Äì2022 BASELINE FEATURES\n",
    "#    (NO MEDIAN VALUES, NO 2023 COLUMNS)\n",
    "# ==========================================\n",
    "baseline_21_22_raw = [\n",
    "    \"Total_Population_2021\", \"Median_Household_Income_2021\",\n",
    "    #\"Median_Housing_Value_2021\",  # EXCLUDED\n",
    "    \"Owner_Occupied_Units_2021\",\n",
    "    \"Bachelors_Degree_Count_2021\", \"Masters_Degree_Count_2021\",\n",
    "    \"Unemployed_Count_2021\", \"Unemployment_Rate_2021\",\n",
    "    \"Bachelors_Or_Higher_Rate_2021\",\n",
    "\n",
    "    \"Total_Population_2022\", \"Median_Household_Income_2022\",\n",
    "    # \"Median_Housing_Value_2022\",  # EXCLUDED\n",
    "    \"Owner_Occupied_Units_2022\",\n",
    "    \"Bachelors_Degree_Count_2022\", \"Masters_Degree_Count_2022\",\n",
    "    \"Unemployed_Count_2022\", \"Unemployment_Rate_2022\",\n",
    "    \"Bachelors_Or_Higher_Rate_2022\",\n",
    "]\n",
    "\n",
    "# Keep only existing columns and enforce \"no 2023\" + \"no housing values\"\n",
    "baseline_21_22 = []\n",
    "for c in baseline_21_22_raw:\n",
    "    if c not in df.columns:\n",
    "        continue\n",
    "    if \"2023\" in c:\n",
    "        continue\n",
    "    if \"Median_Housing_Value\" in c:\n",
    "        continue\n",
    "    baseline_21_22.append(c)\n",
    "\n",
    "print(\"\\nStrict baseline (2021‚Äì22 only, no medians, no 2023):\")\n",
    "print(baseline_21_22)\n",
    "\n",
    "# ==========================================\n",
    "# 4. IDENTIFY VIBRANCY FEATURES\n",
    "#    (numeric, not baseline, not target, not 2023, not housing values, no events)\n",
    "# ==========================================\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Start exclusion list with baseline + target\n",
    "exclude_from_vibrancy = set(baseline_21_22 + [TARGET_COL])\n",
    "\n",
    "# Exclude any numeric col with 2023 in its name or any housing value column\n",
    "for col in numeric_cols:\n",
    "    if \"2023\" in col:\n",
    "        exclude_from_vibrancy.add(col)\n",
    "    if \"Median_Housing_Value\" in col:\n",
    "        exclude_from_vibrancy.add(col)\n",
    "\n",
    "# Make sure geo/id columns are excluded if numeric (just in case)\n",
    "id_and_geo = [\"city\", \"state\", \"region\", \"Merge_Key\"]\n",
    "for c in id_and_geo:\n",
    "    if c in numeric_cols:\n",
    "        exclude_from_vibrancy.add(c)\n",
    "\n",
    "candidate_vibrancy = [c for c in numeric_cols if c not in exclude_from_vibrancy]\n",
    "\n",
    "# Drop event-based features\n",
    "candidate_vibrancy = [c for c in candidate_vibrancy if \"_events\" not in c]\n",
    "\n",
    "# Treat fortune & sbs as vibrancy if present\n",
    "for special in [\"fortune\", \"sbs\"]:\n",
    "    if special in df.columns and special not in candidate_vibrancy:\n",
    "        candidate_vibrancy.append(special)\n",
    "\n",
    "vibrancy_cols = candidate_vibrancy\n",
    "\n",
    "print(\"\\nNumber of vibrancy features (no events, no 2023, no medians):\", len(vibrancy_cols))\n",
    "print(\"First 20 vibrancy cols:\", vibrancy_cols[:20])\n",
    "\n",
    "# Final sanity checks\n",
    "all_features_for_check = baseline_21_22 + vibrancy_cols\n",
    "assert not any(\"2023\" in c for c in all_features_for_check), \"Found 2023 column in feature set!\"\n",
    "assert not any(\"Median_Housing_Value\" in c for c in all_features_for_check), \"Found housing value column in feature set!\"\n",
    "\n",
    "# Geographic categorical columns\n",
    "geo_cols = [\"state\", \"region\"]\n",
    "\n",
    "# ==========================================\n",
    "# 5. BUILD FEATURE MATRICES FOR MODELS\n",
    "# ==========================================\n",
    "feature_cols_A = baseline_21_22 + geo_cols              # no vibrancy\n",
    "feature_cols_B = baseline_21_22 + vibrancy_cols + geo_cols  # with vibrancy\n",
    "\n",
    "feature_cols_A = [c for c in feature_cols_A if c in df.columns]\n",
    "feature_cols_B = [c for c in feature_cols_B if c in df.columns]\n",
    "\n",
    "print(\"\\nFeature counts:\")\n",
    "print(\"Model A (no vibrancy):\", len(feature_cols_A))\n",
    "print(\"Model B (with vibrancy):\", len(feature_cols_B))\n",
    "\n",
    "X_A = df[feature_cols_A].copy()\n",
    "X_B = df[feature_cols_B].copy()\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "indices = np.arange(len(df))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_A_train, X_A_test = X_A.iloc[train_idx], X_A.iloc[test_idx]\n",
    "X_B_train, X_B_test = X_B.iloc[train_idx], X_B.iloc[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "print(\"\\nTrain/Test sizes:\")\n",
    "print(\"X_A:\", X_A_train.shape, X_A_test.shape)\n",
    "print(\"X_B:\", X_B_train.shape, X_B_test.shape)\n",
    "\n",
    "# ==========================================\n",
    "# 6. ROBUST ONE-HOT ENCODER\n",
    "# ==========================================\n",
    "def make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# ==========================================\n",
    "# 7. BUILD XGBOOST PIPELINE\n",
    "# ==========================================\n",
    "def build_xgb_strict(baseline_cols, vibrancy_cols, geo_cols, use_vibrancy=True):\n",
    "    transformers = []\n",
    "\n",
    "    numeric_baseline = [c for c in baseline_cols if c in df.columns]\n",
    "    if numeric_baseline:\n",
    "        transformers.append(\n",
    "            (\"baseline\",\n",
    "             Pipeline(steps=[\n",
    "                 (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "             ]),\n",
    "             numeric_baseline)\n",
    "        )\n",
    "\n",
    "    numeric_vibrancy = [c for c in vibrancy_cols if c in df.columns] if use_vibrancy else []\n",
    "    if use_vibrancy and numeric_vibrancy:\n",
    "        transformers.append(\n",
    "            (\"vibrancy\",\n",
    "             Pipeline(steps=[\n",
    "                 (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "             ]),\n",
    "             numeric_vibrancy)\n",
    "        )\n",
    "\n",
    "    geo = [g for g in geo_cols if g in df.columns]\n",
    "    if geo:\n",
    "        transformers.append(\n",
    "            (\"geo\",\n",
    "             make_ohe(),\n",
    "             geo)\n",
    "        )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"pre\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "pipe_A = build_xgb_strict(baseline_21_22, [], geo_cols, use_vibrancy=False)\n",
    "pipe_B = build_xgb_strict(baseline_21_22, vibrancy_cols, geo_cols, use_vibrancy=True)\n",
    "\n",
    "# ==========================================\n",
    "# 8. HOLDOUT EVAL\n",
    "# ==========================================\n",
    "def eval_holdout(name, pipe, X_tr, X_te, y_tr, y_te):\n",
    "    print(f\"\\nüß† Training {name} (holdout) ...\")\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    pred_tr = pipe.predict(X_tr)\n",
    "    pred_te = pipe.predict(X_te)\n",
    "\n",
    "    rmse_tr = mean_squared_error(y_tr, pred_tr) ** 0.5\n",
    "    rmse_te = mean_squared_error(y_te, pred_te) ** 0.5\n",
    "    mae_tr = mean_absolute_error(y_tr, pred_tr)\n",
    "    mae_te = mean_absolute_error(y_te, pred_te)\n",
    "    r2_tr = r2_score(y_tr, pred_tr)\n",
    "    r2_te = r2_score(y_te, pred_te)\n",
    "\n",
    "    print(f\"  Train -> RMSE: {rmse_tr:,.2f}, MAE: {mae_tr:,.2f}, R¬≤: {r2_tr:.3f}\")\n",
    "    print(f\"  Test  -> RMSE: {rmse_te:,.2f}, MAE: {mae_te:,.2f}, R¬≤: {r2_te:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"rmse_train\": rmse_tr,\n",
    "        \"rmse_test\": rmse_te,\n",
    "        \"mae_train\": mae_tr,\n",
    "        \"mae_test\": mae_te,\n",
    "        \"r2_train\": r2_tr,\n",
    "        \"r2_test\": r2_te,\n",
    "        \"fitted_pipeline\": pipe\n",
    "    }\n",
    "\n",
    "# ==========================================\n",
    "# 9. K-FOLD CV EVAL\n",
    "# ==========================================\n",
    "def eval_cv(name, pipe, X, y, n_splits=N_SPLITS):\n",
    "    print(f\"\\nüîÅ {name} ‚Äì {n_splits}-fold cross-validation ...\")\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    mse_scores = cross_val_score(pipe, X, y, cv=cv,\n",
    "                                 scoring=\"neg_mean_squared_error\",\n",
    "                                 n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "    mae_scores = cross_val_score(pipe, X, y, cv=cv,\n",
    "                                 scoring=\"neg_mean_absolute_error\",\n",
    "                                 n_jobs=-1)\n",
    "    mae_scores = -mae_scores\n",
    "\n",
    "    r2_scores = cross_val_score(pipe, X, y, cv=cv,\n",
    "                                scoring=\"r2\",\n",
    "                                n_jobs=-1)\n",
    "\n",
    "    print(f\"  CV RMSE: mean={rmse_scores.mean():,.2f}, std={rmse_scores.std():.2f}\")\n",
    "    print(f\"  CV MAE : mean={mae_scores.mean():,.2f}, std={mae_scores.std():.2f}\")\n",
    "    print(f\"  CV R¬≤  : mean={r2_scores.mean():.3f}, std={r2_scores.std():.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": name + \" (CV)\",\n",
    "        \"rmse_mean\": rmse_scores.mean(),\n",
    "        \"rmse_std\": rmse_scores.std(),\n",
    "        \"mae_mean\": mae_scores.mean(),\n",
    "        \"mae_std\": mae_scores.std(),\n",
    "        \"r2_mean\": r2_scores.mean(),\n",
    "        \"r2_std\": r2_scores.std(),\n",
    "    }\n",
    "\n",
    "# ==========================================\n",
    "# 10. RUN ‚Äì HOLDOUT + CV\n",
    "# ==========================================\n",
    "results_holdout = []\n",
    "results_cv = []\n",
    "\n",
    "res_A_hold = eval_holdout(\"XGB_A (21‚Äì22 ACS + geo, no vibrancy)\",\n",
    "                          pipe_A, X_A_train, X_A_test, y_train, y_test)\n",
    "results_holdout.append(res_A_hold)\n",
    "\n",
    "res_A_cv = eval_cv(\"XGB_A (21‚Äì22 ACS + geo, no vibrancy)\", pipe_A, X_A, y)\n",
    "results_cv.append(res_A_cv)\n",
    "\n",
    "res_B_hold = eval_holdout(\"XGB_B (21‚Äì22 ACS + geo + vibrancy)\",\n",
    "                          pipe_B, X_B_train, X_B_test, y_train, y_test)\n",
    "results_holdout.append(res_B_hold)\n",
    "\n",
    "res_B_cv = eval_cv(\"XGB_B (21‚Äì22 ACS + geo + vibrancy)\", pipe_B, X_B, y)\n",
    "results_cv.append(res_B_cv)\n",
    "\n",
    "print(\"\\n\\n================ HOLDOUT SUMMARY ================\")\n",
    "print(pd.DataFrame([\n",
    "    {\n",
    "        \"model\": r[\"model\"],\n",
    "        \"rmse_train\": r[\"rmse_train\"],\n",
    "        \"rmse_test\": r[\"rmse_test\"],\n",
    "        \"mae_train\": r[\"mae_train\"],\n",
    "        \"mae_test\": r[\"mae_test\"],\n",
    "        \"r2_train\": r[\"r2_train\"],\n",
    "        \"r2_test\": r[\"r2_test\"],\n",
    "    }\n",
    "    for r in results_holdout\n",
    "]))\n",
    "\n",
    "print(\"\\n================ CV SUMMARY ================\")\n",
    "print(pd.DataFrame(results_cv))\n",
    "\n",
    "# ==========================================\n",
    "# 11. FEATURE IMPORTANCES\n",
    "# ==========================================\n",
    "def extract_importances(pipe, baseline_cols, vibrancy_cols):\n",
    "    model = pipe.named_steps[\"model\"]\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    n_base = len(baseline_cols)\n",
    "    n_vib = len(vibrancy_cols)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # baseline chunk\n",
    "    for i, col in enumerate(baseline_cols):\n",
    "        if i < len(importances):\n",
    "            rows.append({\"feature\": col, \"group\": \"baseline\",\n",
    "                         \"importance\": importances[i]})\n",
    "\n",
    "    # vibrancy chunk\n",
    "    start_v = n_base\n",
    "    for j, col in enumerate(vibrancy_cols):\n",
    "        idx = start_v + j\n",
    "        if idx < len(importances):\n",
    "            rows.append({\"feature\": col, \"group\": \"vibrancy\",\n",
    "                         \"importance\": importances[idx]})\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# fit on full data for stable importances\n",
    "pipe_A_full = build_xgb_strict(baseline_21_22, [], geo_cols, use_vibrancy=False)\n",
    "pipe_A_full.fit(X_A, y)\n",
    "\n",
    "pipe_B_full = build_xgb_strict(baseline_21_22, vibrancy_cols, geo_cols, use_vibrancy=True)\n",
    "pipe_B_full.fit(X_B, y)\n",
    "\n",
    "imp_A = extract_importances(pipe_A_full, baseline_21_22, [])\n",
    "imp_B = extract_importances(pipe_B_full, baseline_21_22, vibrancy_cols)\n",
    "\n",
    "print(\"\\nüîç Top 10 feature importances ‚Äì Model A (no vibrancy):\")\n",
    "print(imp_A.head(10))\n",
    "\n",
    "print(\"\\nüîç Top 25 feature importances ‚Äì Model B (with vibrancy):\")\n",
    "print(imp_B.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798e1dc-012a-4b21-900b-dc9384ebc189",
   "metadata": {},
   "source": [
    "Slide deck charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cb4e7-07af-4500-ab5e-698be5034610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================\n",
    "# 1. Hard-code your metrics from the four tables\n",
    "#    (numbers are from your slides)\n",
    "# ======================================================\n",
    "\n",
    "models = [\"Linear\\nRegression\", \"Ridge\", \"Lasso\", \"Random\\nForest\", \"Neural\\nNetwork\", \"XGBoost\"]\n",
    "\n",
    "# --- WITHOUT VIBE (no geo vs geo) ---\n",
    "r2_no_vibe_no_geo = {\n",
    "    \"Linear\\nRegression\": 0.40,\n",
    "    \"Ridge\": 0.49,\n",
    "    \"Lasso\": 0.03,\n",
    "    \"Random\\nForest\": 0.60,\n",
    "    \"Neural\\nNetwork\": 0.70,\n",
    "    \"XGBoost\": 0.81,\n",
    "}\n",
    "\n",
    "rmse_no_vibe_no_geo = {\n",
    "    \"Linear\\nRegression\": 181948,\n",
    "    \"Ridge\": 167559,\n",
    "    \"Lasso\": 230898,\n",
    "    \"Random\\nForest\": 147905,\n",
    "    \"Neural\\nNetwork\": 143621,\n",
    "    \"XGBoost\": 159899,\n",
    "}\n",
    "\n",
    "r2_no_vibe_geo = {\n",
    "    \"Linear\\nRegression\": 0.78,\n",
    "    \"Ridge\": 0.69,\n",
    "    \"Lasso\": 0.72,\n",
    "    \"Random\\nForest\": 0.81,\n",
    "    \"Neural\\nNetwork\": 0.78,\n",
    "    \"XGBoost\": 0.81,\n",
    "}\n",
    "\n",
    "rmse_no_vibe_geo = {\n",
    "    \"Linear\\nRegression\": 161760,\n",
    "    \"Ridge\": 189438,\n",
    "    \"Lasso\": 178670,\n",
    "    \"Random\\nForest\": 152033,\n",
    "    \"Neural\\nNetwork\": 124968,\n",
    "    \"XGBoost\": 146499,\n",
    "}\n",
    "\n",
    "# --- WITH VIBE (no geo vs geo) ---\n",
    "r2_vibe_no_geo = {\n",
    "    \"Linear\\nRegression\": 0.12,\n",
    "    \"Ridge\": 0.51,\n",
    "    \"Lasso\": 0.54,\n",
    "    \"Random\\nForest\": 0.61,\n",
    "    \"Neural\\nNetwork\": 0.67,\n",
    "    \"XGBoost\": 0.82,\n",
    "}\n",
    "\n",
    "rmse_vibe_no_geo = {\n",
    "    \"Linear\\nRegression\": 220837,\n",
    "    \"Ridge\": 164122,\n",
    "    \"Lasso\": 159371,\n",
    "    \"Random\\nForest\": 146109,\n",
    "    \"Neural\\nNetwork\": 151792,\n",
    "    \"XGBoost\": 153570,\n",
    "}\n",
    "\n",
    "r2_vibe_geo = {\n",
    "    \"Linear\\nRegression\": 0.38,\n",
    "    \"Ridge\": 0.70,\n",
    "    \"Lasso\": 0.76,\n",
    "    \"Random\\nForest\": 0.77,\n",
    "    \"Neural\\nNetwork\": 0.78,\n",
    "    \"XGBoost\": 0.91,\n",
    "}\n",
    "\n",
    "rmse_vibe_geo = {\n",
    "    \"Linear\\nRegression\": 176170,\n",
    "    \"Ridge\": 172529,\n",
    "    \"Lasso\": 156543,\n",
    "    \"Random\\nForest\": 164019,\n",
    "    \"Neural\\nNetwork\": 123918,\n",
    "    \"XGBoost\": 100608,\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 2. Helper ‚Äì build ‚Äúimprovement‚Äù arrays for all models\n",
    "# ======================================================\n",
    "def compute_improvement(models, before_dict, after_dict, metric=\"r2\"):\n",
    "    \"\"\"\n",
    "    metric='r2'  -> improvement = after - before  (higher is better)\n",
    "    metric='rmse'-> improvement = before - after  (reduction, so positive is better)\n",
    "    \"\"\"\n",
    "    deltas = []\n",
    "    for m in models:\n",
    "        before = before_dict[m]\n",
    "        after = after_dict[m]\n",
    "        if metric == \"r2\":\n",
    "            delta = after - before\n",
    "        else:  # rmse\n",
    "            delta = before - after\n",
    "        deltas.append(delta)\n",
    "    return np.array(deltas)\n",
    "\n",
    "# compute all four sets\n",
    "delta_r2_no_vibe  = compute_improvement(models, r2_no_vibe_no_geo,  r2_no_vibe_geo,  metric=\"r2\")\n",
    "delta_rmse_no_vibe = compute_improvement(models, rmse_no_vibe_no_geo, rmse_no_vibe_geo, metric=\"rmse\")\n",
    "\n",
    "delta_r2_vibe  = compute_improvement(models, r2_vibe_no_geo,  r2_vibe_geo,  metric=\"r2\")\n",
    "delta_rmse_vibe = compute_improvement(models, rmse_vibe_no_geo, rmse_vibe_geo, metric=\"rmse\")\n",
    "\n",
    "# ======================================================\n",
    "# 3. Generic plotting helper (one chart)\n",
    "# ======================================================\n",
    "def plot_improvement_bar(models, deltas, title, ylabel, is_money=False):\n",
    "    x = np.arange(len(models))\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "    bars = ax.bar(x, deltas)\n",
    "\n",
    "    # annotate bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        if is_money:\n",
    "            text = f\"+${height:,.0f}\"\n",
    "        else:\n",
    "            text = f\"+{height:.2f}\"\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (0.02 * max(deltas)),\n",
    "            text,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=0)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ======================================================\n",
    "# 4. Plot the four requested charts\n",
    "# ======================================================\n",
    "\n",
    "# 1) No Vibe ‚Äì R^2 gain from adding geo\n",
    "plot_improvement_bar(\n",
    "    models,\n",
    "    delta_r2_no_vibe,\n",
    "    title=\"R¬≤ Improvement from Adding Geo (No Vibe)\",\n",
    "    ylabel=\"Œî R¬≤\",\n",
    "    is_money=False,\n",
    ")\n",
    "\n",
    "# 2) No Vibe ‚Äì RMSE reduction from adding geo\n",
    "plot_improvement_bar(\n",
    "    models,\n",
    "    delta_rmse_no_vibe,\n",
    "    title=\"RMSE Reduction from Adding Geo (No Vibe)\",\n",
    "    ylabel=\"Œî RMSE (‚Üì is better)\",\n",
    "    is_money=True,\n",
    ")\n",
    "\n",
    "# 3) With Vibe ‚Äì R^2 gain from adding geo\n",
    "plot_improvement_bar(\n",
    "    models,\n",
    "    delta_r2_vibe,\n",
    "    title=\"R¬≤ Improvement from Adding Geo (With Vibe)\",\n",
    "    ylabel=\"Œî R¬≤\",\n",
    "    is_money=False,\n",
    ")\n",
    "\n",
    "# 4) With Vibe ‚Äì RMSE reduction from adding geo\n",
    "plot_improvement_bar(\n",
    "    models,\n",
    "    delta_rmse_vibe,\n",
    "    title=\"RMSE Reduction from Adding Geo (With Vibe)\",\n",
    "    ylabel=\"Œî RMSE (‚Üì is better)\",\n",
    "    is_money=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f2e86-f10a-47d1-8072-8e01ecd175de",
   "metadata": {},
   "source": [
    "Feature importance XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa541fc-acbb-4702-bbbd-05265fe376a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Prepare top-25 importance\n",
    "# -----------------------------\n",
    "top_n = 25\n",
    "topB = imp_B.head(top_n).copy()\n",
    "\n",
    "# Reverse for nicer top-to-bottom layout\n",
    "topB = topB.iloc[::-1]\n",
    "\n",
    "features = topB[\"feature\"].values\n",
    "importances = topB[\"importance\"].values\n",
    "groups = topB[\"group\"].values  # \"baseline\" or \"vibrancy\"\n",
    "\n",
    "y_pos = np.arange(len(features))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Build hatch patterns so we can see\n",
    "#    baseline vs vibrancy without colors\n",
    "# -----------------------------\n",
    "hatches = []\n",
    "for g in groups:\n",
    "    if g == \"baseline\":\n",
    "        hatches.append(\"///\")     # slanted stripes\n",
    "    else:  # vibrancy\n",
    "        hatches.append(\"\")        # solid bar\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Plot horizontal bar chart\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "bars = ax.barh(y_pos, importances)\n",
    "\n",
    "# apply hatches + simple legend\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# Legend proxy artists\n",
    "from matplotlib.patches import Patch\n",
    "legend_handles = [\n",
    "    Patch(hatch=\"///\", label=\"Baseline (ACS)\"),\n",
    "    Patch(hatch=\"\", label=\"Vibrancy (food, venues, etc.)\"),\n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_handles, loc=\"lower right\", frameon=False)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(features)\n",
    "ax.set_xlabel(\"Feature Importance (XGBoost gain)\")\n",
    "ax.set_title(\"Top 25 Feature Importances ‚Äì Model B (with Vibrancy)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b3b41-0588-4b8a-8296-a3a272bc93cb",
   "metadata": {},
   "source": [
    "More slide deck visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8f2e2-a6c7-4a4c-8974-8eef994e5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================\n",
    "# 1. DATA TABLES (CLEANED & READY)\n",
    "# ============================================\n",
    "\n",
    "# ---- No Vibe, No Geo ----\n",
    "no_vibe_no_geo = pd.DataFrame({\n",
    "    \"Model\": [\"Linear Regression\", \"Ridge\", \"Lasso\", \"Random Forest\", \"Neural Network\", \"XGBoost\"],\n",
    "    \"R2\": [0.52, 0.50, 0.48, 0.68, 0.70, 0.68],\n",
    "    \"RMSE\": [235814, 240616, 245513, 192728, 143621, 191111]\n",
    "})\n",
    "\n",
    "# ---- No Vibe, With Geo ----\n",
    "no_vibe_with_geo = pd.DataFrame({\n",
    "    \"Model\": [\"Linear Regression\", \"Ridge\", \"Lasso\", \"Random Forest\", \"Neural Network\", \"XGBoost\"],\n",
    "    \"R2\": [0.78, 0.69, 0.72, 0.81, 0.78, 0.81],\n",
    "    \"RMSE\": [161760, 189438, 178670, 152033, 124968, 146499]\n",
    "})\n",
    "\n",
    "# ---- With Vibe, No Geo ----\n",
    "vibe_no_geo = pd.DataFrame({\n",
    "    \"Model\": [\"Linear Regression\", \"Ridge\", \"Lasso\", \"Random Forest\", \"Neural Network\", \"XGBoost\"],\n",
    "    \"R2\": [0.54, 0.64, 0.65, 0.64, 0.67, 0.82],\n",
    "    \"RMSE\": [231058, 204410, 201592,140049, 151792, 141009]\n",
    "})\n",
    "\n",
    "# ---- With Vibe, With Geo ----\n",
    "vibe_with_geo = pd.DataFrame({\n",
    "    \"Model\": [\"Linear Regression\", \"Ridge\", \"Lasso\", \"Random Forest\", \"Neural Network\", \"XGBoost\"],\n",
    "    \"R2\": [0.38, 0.70, 0.76, 0.77, 0.78, 0.91],\n",
    "    \"RMSE\": [176170, 172529, 156543, 164019, 123918, 100608]\n",
    "})\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. UNIVERSAL BAR COMPARISON FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def bar_compare(df_before, df_after, metric, title):\n",
    "    models = df_before[\"Model\"]\n",
    "    before_vals = df_before[metric]\n",
    "    after_vals = df_after[metric]\n",
    "\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x - width/2, before_vals, width, label=\"Before Geo\", alpha=0.8)\n",
    "    plt.bar(x + width/2, after_vals, width, label=\"After Geo\", alpha=0.8)\n",
    "\n",
    "    plt.xticks(x, models, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. GENERATE ALL 4 PLOTS\n",
    "# ============================================\n",
    "\n",
    "# ---- 1. No Vibe: R¬≤ ----\n",
    "bar_compare(\n",
    "    no_vibe_no_geo, \n",
    "    no_vibe_with_geo,\n",
    "    metric=\"R2\",\n",
    "    title=\"R¬≤ Improvement from Adding Geographic Features (No Vibrancy)\"\n",
    ")\n",
    "\n",
    "# ---- 2. No Vibe: RMSE ----\n",
    "bar_compare(\n",
    "    no_vibe_no_geo, \n",
    "    no_vibe_with_geo,\n",
    "    metric=\"RMSE\",\n",
    "    title=\"RMSE Reduction from Adding Geographic Features (No Vibrancy)\"\n",
    ")\n",
    "\n",
    "# ---- 3. With Vibe: R¬≤ ----\n",
    "bar_compare(\n",
    "    vibe_no_geo, \n",
    "    vibe_with_geo,\n",
    "    metric=\"R2\",\n",
    "    title=\"R¬≤ Improvement from Adding Geographic Features (With Vibrancy)\"\n",
    ")\n",
    "\n",
    "# ---- 4. With Vibe: RMSE ----\n",
    "bar_compare(\n",
    "    vibe_no_geo, \n",
    "    vibe_with_geo,\n",
    "    metric=\"RMSE\",\n",
    "    title=\"RMSE Reduction from Adding Geographic Features (With Vibrancy)\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp311]",
   "language": "python",
   "name": "conda-env-nlp311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
